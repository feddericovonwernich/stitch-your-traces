package feddericovonwernich.example.storyservice;

import feddericovonwernich.example.storyservice.dto.CreateStoryRequest;
import feddericovonwernich.example.storyservice.dto.SaveStoryRequest;
import feddericovonwernich.example.storyservice.model.StorySource;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.jetbrains.annotations.NotNull;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.boot.test.util.TestPropertyValues;
import org.springframework.context.ApplicationContextInitializer;
import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.http.MediaType;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.web.servlet.MockMvc;
import org.testcontainers.containers.MySQLContainer;
import org.testcontainers.kafka.KafkaContainer;
import org.testcontainers.utility.DockerImageName;

import java.time.Duration;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.CompletableFuture;


import static org.hamcrest.Matchers.hasSize;
import static org.hamcrest.Matchers.is;
import static org.junit.jupiter.api.Assertions.assertTrue;
import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;

@SpringBootTest
@AutoConfigureMockMvc
@ContextConfiguration(initializers = StoryControllerIntegrationTest.Initializer.class)
@ActiveProfiles("test")
class StoryControllerIntegrationTest {

    private static final String STORY_REQUESTS = "story_requests";
    private static final DockerImageName MYSQL_IMAGE = DockerImageName.parse("mysql:8.3.0");
    private static final DockerImageName KAFKA_IMAGE = DockerImageName.parse("apache/kafka-native:3.9.1");

    static final MySQLContainer<?> mysql = new MySQLContainer<>(MYSQL_IMAGE)
            .withDatabaseName("blog_db")
            .withUsername("test")
            .withPassword("test");

    /*
     * Using auto-creation to avoid complexity of maintaining topics.
     */
    static final KafkaContainer kafka = new KafkaContainer(KAFKA_IMAGE);

    /**
     * This initializer runs *before* Spring Bootâ€™s Environment is frozen.
     * It starts the containers, then injects their connection info into the Environment.
     */
    static class Initializer
            implements ApplicationContextInitializer<ConfigurableApplicationContext> {

        @Override
        public void initialize(ConfigurableApplicationContext ctx) {
            // start containers
            mysql.start();
            kafka.start();

            // override properties
            TestPropertyValues.of(
                    "spring.datasource.url=" + mysql.getJdbcUrl(),
                    "spring.datasource.username=" + mysql.getUsername(),
                    "spring.datasource.password=" + mysql.getPassword(),
                    "kafka.bootstrap-servers=" + kafka.getBootstrapServers(),
                    "kafka.publish-topic=" + STORY_REQUESTS
            ).applyTo(ctx.getEnvironment());
        }
    }

    @Autowired MockMvc mvc;
    @Autowired ObjectMapper mapper;

    @Test
    void createHumanRequest_returnsPending_thenCompleteAfterPut() throws Exception {
        // Request an AI story.
        CreateStoryRequest req = new CreateStoryRequest("AI Tale", null, StorySource.HUMAN);

        // Send the request.
        String resp = mvc.perform(post("/stories")
                        .contentType(MediaType.APPLICATION_JSON)
                        .content(mapper.writeValueAsString(req)))
                .andExpect(status().isOk())
                .andExpect(jsonPath("$.status", is("PENDING")))
                .andExpect(jsonPath("$.storyIds", hasSize(0)))
                .andReturn()
                .getResponse()
                .getContentAsString();

        // Extract request id
        Long requestId = mapper.readTree(resp).path("id").asLong();

        // Should still be pending
        mvc.perform(get("/stories/{id}/status", requestId))
                .andExpect(status().isOk())
                .andExpect(jsonPath("$.status", is("PENDING")))
                .andExpect(jsonPath("$.storyIds", hasSize(0)));

        // Simulate Human worker completing story
        SaveStoryRequest saveStoryRequest = new SaveStoryRequest("Generated Title", "Generated by Human");

        mvc.perform(put("/stories/{id}", requestId)
                        .contentType(MediaType.APPLICATION_JSON)
                        .content(mapper.writeValueAsString(saveStoryRequest)))
                .andExpect(status().isOk());

        // Check status is complete
        mvc.perform(get("/stories/{id}/status", requestId))
                .andExpect(status().isOk())
                .andExpect(jsonPath("$.status", is("COMPLETE")))
                .andExpect(jsonPath("$.storyIds", hasSize(1)));

        // Test getting some stories.
        mvc.perform(get("/stories")
                        .param("page", "0")
                        .param("size", "10"))
                .andExpect(status().isOk())
                .andExpect(jsonPath("$.totalElements").isNumber())
                .andExpect(jsonPath("$.totalPages").isNumber());
    }



    @Test
    void createAiRequest_returnsPending_thenCompleteAfterPut() throws Exception {

        // Verify Kafka message
        try (var consumer = new KafkaConsumer<String, String>(getKafkaConsumerProperties())) {

            consumer.subscribe(List.of(STORY_REQUESTS));

            CompletableFuture<Long> futureRequestId = CompletableFuture.supplyAsync(() -> {
                try {
                    return requestAiStory();
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }
            });

            var records = consumer.poll(Duration.ofSeconds(1));

            boolean messageFound = false;

            Long requestId = futureRequestId.get();

            for (var record : records.records("story_requests")) {
                  var jsonNode = mapper.readTree(record.value());
                  if (jsonNode.path("id").asLong() == requestId) {
                      messageFound = true;
                      break;
                  }
            }

            assertTrue(messageFound, "Kafka message for requestId not found");

            // We got the request.

            // Simulate AI worker completing story
            SaveStoryRequest saveStoryRequest = new SaveStoryRequest("Generated Title", "Generated by AI");

            mvc.perform(put("/stories/{id}", requestId)
                            .contentType(MediaType.APPLICATION_JSON)
                            .content(mapper.writeValueAsString(saveStoryRequest)))
                    .andExpect(status().isOk());

            // Check status is complete
            mvc.perform(get("/stories/{id}/status", requestId))
                    .andExpect(status().isOk())
                    .andExpect(jsonPath("$.status", is("COMPLETE")))
                    .andExpect(jsonPath("$.storyIds", hasSize(1)));
        }
    }

    @NotNull
    private Long requestAiStory() throws Exception {
        // Request an AI story.
        CreateStoryRequest req = new CreateStoryRequest("AI Tale", null, StorySource.AI);

        // Send the request.
        String resp = mvc.perform(post("/stories")
                        .contentType(MediaType.APPLICATION_JSON)
                        .content(mapper.writeValueAsString(req)))
                .andExpect(status().isOk())
                .andExpect(jsonPath("$.status", is("PENDING")))
                .andExpect(jsonPath("$.storyIds", hasSize(0)))
                .andReturn()
                .getResponse()
                .getContentAsString();

        // Extract request id
        return mapper.readTree(resp).path("id").asLong();
    }

    private Properties getKafkaConsumerProperties() {
        Properties props = new Properties();
        props.put("bootstrap.servers", kafka.getBootstrapServers());
        props.put("group.id", "test-group");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        return props;
    }

}